{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:39:00.594932Z",
     "iopub.status.busy": "2021-11-06T05:39:00.594519Z",
     "iopub.status.idle": "2021-11-06T05:39:08.843246Z",
     "shell.execute_reply": "2021-11-06T05:39:08.842420Z",
     "shell.execute_reply.started": "2021-11-06T05:39:00.594827Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4bfea9e9385d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer, AutoConfig\n",
    "import itertools\n",
    "import gc\n",
    "import os \n",
    "import random\n",
    "import spacy\n",
    "import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:39:08.846617Z",
     "iopub.status.busy": "2021-11-06T05:39:08.845999Z",
     "iopub.status.idle": "2021-11-06T05:39:08.855421Z",
     "shell.execute_reply": "2021-11-06T05:39:08.854542Z",
     "shell.execute_reply.started": "2021-11-06T05:39:08.846568Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=1326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:39:08.858654Z",
     "iopub.status.busy": "2021-11-06T05:39:08.858354Z",
     "iopub.status.idle": "2021-11-06T05:39:08.865127Z",
     "shell.execute_reply": "2021-11-06T05:39:08.864355Z",
     "shell.execute_reply.started": "2021-11-06T05:39:08.858616Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 13\n",
    "batch_size = 16\n",
    "epochs = 35 # The number of epochs\n",
    "embedding_dim = 300\n",
    "MODEL_NAME =  '../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base'\n",
    "# MODEL_NAME2 =  '../input/huggingface-roberta-variants/roberta-base/roberta-base'\n",
    "# ../input/huggingface-bert/bert-base-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:39:08.867819Z",
     "iopub.status.busy": "2021-11-06T05:39:08.867459Z",
     "iopub.status.idle": "2021-11-06T05:39:08.904430Z",
     "shell.execute_reply": "2021-11-06T05:39:08.903658Z",
     "shell.execute_reply.started": "2021-11-06T05:39:08.867782Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/ohabotdata/OHABotData.csv',sep=',').sample(frac = 1)\n",
    "df = df.dropna()\n",
    "df = df.astype({\"Questions \": str, \"Answers\": int})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OHADataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:39:08.906090Z",
     "iopub.status.busy": "2021-11-06T05:39:08.905689Z",
     "iopub.status.idle": "2021-11-06T05:39:08.912441Z",
     "shell.execute_reply": "2021-11-06T05:39:08.911462Z",
     "shell.execute_reply.started": "2021-11-06T05:39:08.906048Z"
    }
   },
   "outputs": [],
   "source": [
    "class OHADataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.df.iloc[idx][1]\n",
    "        text = self.df.iloc[idx][0]     \n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:39:08.915057Z",
     "iopub.status.busy": "2021-11-06T05:39:08.914137Z",
     "iopub.status.idle": "2021-11-06T05:39:15.673746Z",
     "shell.execute_reply": "2021-11-06T05:39:15.672941Z",
     "shell.execute_reply.started": "2021-11-06T05:39:08.914989Z"
    }
   },
   "outputs": [],
   "source": [
    "class OHAModel(nn.Module):\n",
    "    def __init__(self,path):\n",
    "        super(OHAModel,self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(path)\n",
    "        self.config.update({'output_hidden_states':True})\n",
    "        self.bert = AutoModel.from_pretrained(path,output_hidden_states=False)\n",
    "        \n",
    "\n",
    "        self.linear = nn.Linear(768,num_classes)\n",
    "        self.dropout = nn.Dropout(0.50)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.logSoftmax = nn.LogSoftmax()\n",
    "    \n",
    "\n",
    "    def forward(self,xb):\n",
    "        x = self.bert(**xb)[1]\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.logSoftmax(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "model = OHAModel(MODEL_NAME).to(device)\n",
    "torch.save(model.state_dict(), 'initialModel')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:39:15.675764Z",
     "iopub.status.busy": "2021-11-06T05:39:15.675231Z",
     "iopub.status.idle": "2021-11-06T05:39:15.690462Z",
     "shell.execute_reply": "2021-11-06T05:39:15.689746Z",
     "shell.execute_reply.started": "2021-11-06T05:39:15.675709Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "bptt = 35\n",
    "\n",
    "# We use NLLL loss so that it is easier during inference time. logSoftmax is already applied to output\n",
    "criterion = nn.NLLLoss()\n",
    "lr = 0.00002 # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay= 1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.95, verbose = True)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.95)\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    model.train() # Turn on the train mode\n",
    "    return_loss = []\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "#     src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    batch = 0\n",
    "    for data, targets in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "        data = tokenizer.batch_encode_plus([*data],pad_to_max_length='max_length', return_tensors='pt').to(device)\n",
    "        final_output = model(data)\n",
    "        targets = targets.to(device)\n",
    "        final_output = torch.squeeze(final_output.float())\n",
    "        loss = criterion(final_output, targets)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        return_loss.append(loss.item())\n",
    "        log_interval = 100\n",
    "        batch += 1\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "    return torch.mean(torch.tensor(return_loss))\n",
    "\n",
    "def evaluate(eval_model):\n",
    "#     losses = []\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "#     total_loss = 0.\n",
    "    total_loss = []\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            \n",
    "            data = tokenizer.batch_encode_plus([*data],pad_to_max_length='max_length', return_tensors='pt').to(device)\n",
    "            final_output = model(data)\n",
    "            targets = targets.to(device)\n",
    "            final_output = torch.squeeze(final_output.float())\n",
    "#             loss = criterion(final_output, targets)\n",
    "            currLoss = criterion(final_output, targets).item()\n",
    "#             total_loss += len(data) * currLoss\n",
    "            total_loss.append(currLoss)\n",
    "\n",
    "#     return total_loss\n",
    "    return torch.mean(torch.tensor(total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:39:15.692092Z",
     "iopub.status.busy": "2021-11-06T05:39:15.691725Z",
     "iopub.status.idle": "2021-11-06T05:41:59.629816Z",
     "shell.execute_reply": "2021-11-06T05:41:59.629069Z",
     "shell.execute_reply.started": "2021-11-06T05:39:15.692044Z"
    }
   },
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "train_data = OHADataset(df)\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "val_data = OHADataset(df)\n",
    "val_loader = DataLoader(val_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss = train(model)\n",
    "    val_loss = evaluate(model)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '.format(epoch, (time.time() - epoch_start_time),val_loss))\n",
    "    print('-' * 89)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "        torch.save(best_model, 'bestModel')\n",
    "\n",
    "    scheduler.step()\n",
    "    val_losses.append(val_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "#     print('Hi')\n",
    "#     print(train_losses)\n",
    "#     print('*' * 80)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        plt.plot(train_losses, label = \"Train_Loss\")\n",
    "        plt.plot(val_losses, label = \"Val_Loss\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:41:59.631506Z",
     "iopub.status.busy": "2021-11-06T05:41:59.631250Z",
     "iopub.status.idle": "2021-11-06T05:41:59.636025Z",
     "shell.execute_reply": "2021-11-06T05:41:59.635109Z",
     "shell.execute_reply.started": "2021-11-06T05:41:59.631470Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data = CommonLitDataset(df)\n",
    "# train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load('initialModel'))\n",
    "\n",
    "# for epoch in range(1, best_epoch + 1):\n",
    "# # for epoch in range(1, 8 + 1):\n",
    "#         print('-' * 89)\n",
    "#         print(f'Starting epoch {epoch}')\n",
    "#         epoch_start_time = time.time()\n",
    "#         train_loss = train(model)\n",
    "#         print(f'| end of epoch: {epoch} | time: {time.time() - epoch_start_time}s  | train loss: {train_loss} |')\n",
    "#         print('-' * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:41:59.639454Z",
     "iopub.status.busy": "2021-11-06T05:41:59.638887Z",
     "iopub.status.idle": "2021-11-06T05:42:00.328273Z",
     "shell.execute_reply": "2021-11-06T05:42:00.327367Z",
     "shell.execute_reply.started": "2021-11-06T05:41:59.639414Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'OHABotModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T05:46:21.575470Z",
     "iopub.status.busy": "2021-11-06T05:46:21.574996Z"
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    with torch.no_grad():\n",
    "        query = input()\n",
    "        data = tokenizer.encode_plus(query,pad_to_max_length='max_length', return_tensors='pt').to(device)\n",
    "#         output = nn.Softmax()(model(data)).cpu()\n",
    "        output = model(data).cpu()\n",
    "        print(output)\n",
    "        pred = np.argmax(np.array(output))\n",
    "        print(2 ** output[0][pred])\n",
    "        print(pred)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
