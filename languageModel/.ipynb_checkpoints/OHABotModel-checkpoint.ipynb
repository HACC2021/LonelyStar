{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-06T10:17:41.929114Z",
     "iopub.status.busy": "2021-06-06T10:17:41.92873Z",
     "iopub.status.idle": "2021-06-06T10:17:41.933109Z",
     "shell.execute_reply": "2021-06-06T10:17:41.932152Z",
     "shell.execute_reply.started": "2021-06-06T10:17:41.929079Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ae5338813827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer, AutoConfig\n",
    "\n",
    "import itertools\n",
    "import gc\n",
    "import os \n",
    "import random\n",
    "\n",
    "import spacy\n",
    "import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-06T10:17:42.523609Z",
     "iopub.status.busy": "2021-06-06T10:17:42.523121Z",
     "iopub.status.idle": "2021-06-06T10:17:42.545671Z",
     "shell.execute_reply": "2021-06-06T10:17:42.544293Z",
     "shell.execute_reply.started": "2021-06-06T10:17:42.523562Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=1326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # for TPU\n",
    "# device = xm.xla_device()\n",
    "# torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 15 # The number of epochs\n",
    "embedding_dim = 300\n",
    "MODEL_NAME =  '../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base'\n",
    "# MODEL_NAME2 =  '../input/huggingface-roberta-variants/roberta-base/roberta-base'\n",
    "\n",
    "# ../input/huggingface-bert/bert-base-cased\n",
    "MODEL_NAME2 = None\n",
    "useFeatures = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datadir = '/kaggle/input/commonlitreadabilityprize'\n",
    "# traindir = datadir + '/train.csv'\n",
    "df = pd.read_csv('OHABotData.csv').sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OHADataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonLitDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.df.iloc[idx][1]\n",
    "        text = self.df.iloc[idx][0]     \n",
    "        if useFeatures:\n",
    "            readability = np.array([x for x in self.df.iloc[idx][2:].values])\n",
    "        else:\n",
    "            readability = torch.zeros((1,7))\n",
    "#         print(readability)\n",
    "#         print(type(readability))\n",
    "#         print(readability.shape)\n",
    "        return text, label, readability\n",
    "    \n",
    "\n",
    "    \n",
    "# train_data = CommonLitDataset(df)\n",
    "# train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "# val_data = CommonLitDataset(df)\n",
    "# val_dataloader = DataLoader(val_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "KFold_data = CommonLitDataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ass CommonLitModel(nn.Module):\n",
    "    def __init__(self,path, path2 = None):\n",
    "        super(CommonLitModel,self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(path)\n",
    "        self.config.update({'output_hidden_states':True})\n",
    "        self.bert = AutoModel.from_pretrained(path,output_hidden_states=False)\n",
    "        \n",
    "        if path2:\n",
    "            self.bert2 = AutoModel.from_pretrained(path2, output_hidden_states = False) \n",
    "            self.linear1 = nn.Linear(1536,1536)\n",
    "            self.linear2 = nn.Linear(1536,1)\n",
    "        else:\n",
    "            print('768 Features used')\n",
    "            self.linear1 = nn.Linear(768,768)\n",
    "            self.linear2 = nn.Linear(768,1)\n",
    "            \n",
    "            \n",
    "        self.linear = nn.Linear(775,1)   \n",
    "        self.dropout = nn.Dropout(0.50)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "    \n",
    "\n",
    "    def forward(self,xb, x2 = None, readability = None):\n",
    "        x = self.bert(**xb)[1]\n",
    "        if x2:\n",
    "            x1 = self.bert2(**x2)[1]\n",
    "            x = torch.cat((x, x1))\n",
    "#             x = torch.mean(torch.stack([x, x1]))\n",
    "        \n",
    "#         x = self.dropout(x)\n",
    "#         x = self.linear1(x)\n",
    "#         x = self.lrelu(x) \n",
    "#         print(x.size())\n",
    "#         print(readability.size())\n",
    "        if useFeatures:\n",
    "            x = torch.cat((x,readability),1)\n",
    "            x = self.dropout(x)\n",
    "            x = self.linear(x)\n",
    "        else:\n",
    "            x = self.dropout(x)\n",
    "            x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "model = CommonLitModel(MODEL_NAME,MODEL_NAME2).to(device)\n",
    "torch.save(model.state_dict(), 'initialModel')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if MODEL_NAME2:\n",
    "    tokenizer2 = AutoTokenizer.from_pretrained(MODEL_NAME2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "bptt = 35\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "lr = 0.00002 # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay= 1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.95, verbose = True)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.95)\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    model.train() # Turn on the train mode\n",
    "    return_loss = []\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "#     src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    batch = 0\n",
    "    for data, targets, readability in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "        data1 = tokenizer.batch_encode_plus([*data],pad_to_max_length='max_length', return_tensors='pt').to(device)\n",
    "        readability = torch.tensor(readability).float().to(device)\n",
    "        if MODEL_NAME2:\n",
    "            data2 = tokenizer2.batch_encode_plus([*data],pad_to_max_length='max_length', return_tensors='pt').to(device)\n",
    "            final_output = model(data1 ,data2)\n",
    "            \n",
    "        else:\n",
    "            final_output = model(data1 ,None, readability)\n",
    "        targets = targets.float().to(device)\n",
    "        final_output = torch.squeeze(final_output.float())\n",
    "        loss = criterion(final_output, targets)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        return_loss.append(loss.item())\n",
    "        log_interval = 100\n",
    "        batch += 1\n",
    "#         if batch % log_interval == 0 and batch > 0:\n",
    "#             cur_loss = total_loss / log_interval\n",
    "#             elapsed = time.time() - start_time\n",
    "#             print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "#                   'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "#                   'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "#                     epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n",
    "#                     elapsed * 1000 / log_interval,\n",
    "#                     cur_loss, np.exp(cur_loss)))\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "    return torch.mean(torch.tensor(return_loss))\n",
    "\n",
    "def evaluate(eval_model):\n",
    "#     losses = []\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "#     total_loss = 0.\n",
    "    total_loss = []\n",
    "    with torch.no_grad():\n",
    "        for data, targets, readability in val_loader:\n",
    "            \n",
    "            data1 = tokenizer.batch_encode_plus([*data],pad_to_max_length='max_length', return_tensors='pt').to(device)\n",
    "            readability = torch.tensor(readability).float().to(device)\n",
    "            if MODEL_NAME2:\n",
    "                data2 = tokenizer2.batch_encode_plus([*data],pad_to_max_length='max_length', return_tensors='pt').to(device)\n",
    "                final_output = model(data1 ,data2)\n",
    "            else:\n",
    "                final_output = model(data1 , None, readability)\n",
    "            targets = targets.float().to(device)\n",
    "            final_output = torch.squeeze(final_output.float())\n",
    "#             loss = criterion(final_output, targets)\n",
    "            currLoss = criterion(final_output, targets).item()\n",
    "#             total_loss += len(data) * currLoss\n",
    "            total_loss.append(currLoss)\n",
    "\n",
    "#     return total_loss\n",
    "    return torch.mean(torch.tensor(total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_val_loss = float(\"inf\")\n",
    "# best_model = None\n",
    "\n",
    "# train_data = CommonLitDataset(df)\n",
    "# train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "# val_data = CommonLitDataset(df)\n",
    "# val_dataloader = DataLoader(val_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     epoch_start_time = time.time()\n",
    "#     train_loss = train(best_val_loss)\n",
    "#     val_loss = evaluate(model)\n",
    "#     print('-' * 89)\n",
    "#     print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '.format(epoch, (time.time() - epoch_start_time),val_loss))\n",
    "#     print('-' * 89)\n",
    "    \n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         best_model = model\n",
    "#         torch.save(best_model, 'bestModel')\n",
    "\n",
    "#     scheduler.step()\n",
    "#     val_losses.append(val_loss)\n",
    "#     train_losses.append(train_loss)\n",
    "    \n",
    "# #     print('Hi')\n",
    "# #     print(train_losses)\n",
    "# #     print('*' * 80)\n",
    "\n",
    "#     if epoch % 5 == 0:\n",
    "#         plt.plot(train_losses, label = \"Train_Loss\")\n",
    "#         plt.plot(val_losses, label = \"Val_Loss\")\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CommonLitDataset(df)\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('initialModel'))\n",
    "\n",
    "for epoch in range(1, best_epoch + 1):\n",
    "# for epoch in range(1, 8 + 1):\n",
    "        print('-' * 89)\n",
    "        print(f'Starting epoch {epoch}')\n",
    "        epoch_start_time = time.time()\n",
    "        train_loss = train(model)\n",
    "        print(f'| end of epoch: {epoch} | time: {time.time() - epoch_start_time}s  | train loss: {train_loss} |')\n",
    "        print('-' * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'bestModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0f8dc15da39badb292b88c5300eba9d111afb47f07510baceaf6a8d5a869958a5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
